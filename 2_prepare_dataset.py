import numpy as np
import os
from tensorflow.keras.utils import to_categorical
from tqdm import tqdm

KEYPOINT_DIR = 'gesture_data/keypoints'
OUTPUT_DIR = 'gesture_data'
SEQUENCE_LENGTH = 30

def prepare_dataset():
    X = []
    y = []
    action_map = {}  # √Ånh x·∫° t√™n c·ª≠ ch·ªâ -> s·ªë
    all_actions = set()  # T·∫≠p h·ª£p t·∫•t c·∫£ c√°c c·ª≠ ch·ªâ
    
    # B∆∞·ªõc 1: Thu th·∫≠p t·∫•t c·∫£ c√°c c·ª≠ ch·ªâ duy nh·∫•t
    for filename in os.listdir(KEYPOINT_DIR):
        if filename.endswith('.npy'):
            # T√°ch t√™n c·ª≠ ch·ªâ t·ª´ filename (format: GESTURE_X.npy)
            action_name = '_'.join(filename.split('_')[:-1])
            all_actions.add(action_name)
    
    if not all_actions:
        print("‚ùå Kh√¥ng t√¨m th·∫•y file .npy n√†o trong th∆∞ m·ª•c keypoints")
        return
    
    all_actions = sorted(list(all_actions))  # Chuy·ªÉn th√†nh list v√† s·∫Øp x·∫øp
    action_map = {action: idx for idx, action in enumerate(all_actions)}
    
    print(f"üìå T√¨m th·∫•y {len(all_actions)} c·ª≠ ch·ªâ: {all_actions}")

    # B∆∞·ªõc 2: X·ª≠ l√Ω t·ª´ng file
    valid_files = 0
    for filename in tqdm(os.listdir(KEYPOINT_DIR), desc="Processing files"):
        if not filename.endswith('.npy'):
            continue
        
        # L·∫•y t√™n c·ª≠ ch·ªâ t·ª´ t√™n file
        action_name = '_'.join(filename.split('_')[:-1])
        if action_name not in action_map:
            continue
        
        file_path = os.path.join(KEYPOINT_DIR, filename)
        keypoints = np.load(file_path)
        
        # X·ª≠ l√Ω sequence length
        if keypoints.shape[0] < SEQUENCE_LENGTH:
            # Padding v·ªõi zeros n·∫øu thi·∫øu
            pad_shape = (SEQUENCE_LENGTH - keypoints.shape[0],) + keypoints.shape[1:]
            padding = np.zeros(pad_shape)
            keypoints = np.concatenate((keypoints, padding), axis=0)
        elif keypoints.shape[0] > SEQUENCE_LENGTH:
            # L·∫•y m·∫´u ƒë·ªÅu n·∫øu d∆∞
            indices = np.linspace(0, keypoints.shape[0]-1, num=SEQUENCE_LENGTH, dtype=int)
            keypoints = keypoints[indices]
        
        # Ki·ªÉm tra shape cu·ªëi c√πng
        if keypoints.shape != (SEQUENCE_LENGTH, 1662):
            print(f"\n‚ö†Ô∏è B·ªè qua {filename} do shape kh√¥ng h·ª£p l·ªá: {keypoints.shape}")
            continue
        
        X.append(keypoints)
        y.append(action_map[action_name])
        valid_files += 1
    
    # B∆∞·ªõc 3: L∆∞u d·ªØ li·ªáu
    if not X:
        print("‚ùå Kh√¥ng c√≥ d·ªØ li·ªáu h·ª£p l·ªá n√†o ƒë∆∞·ª£c t·∫°o!")
        return
    
    X = np.array(X)
    y = to_categorical(y)
    
    print("\nüìä Th·ªëng k√™ dataset:")
    print(f"- S·ªë l∆∞·ª£ng m·∫´u: {len(X)}")
    print(f"- Shape X: {X.shape}")
    print(f"- Shape y: {y.shape}")
    print(f"- S·ªë c·ª≠ ch·ªâ: {len(all_actions)}")
    
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    np.save(os.path.join(OUTPUT_DIR, 'X.npy'), X)
    np.save(os.path.join(OUTPUT_DIR, 'y.npy'), y)
    np.save(os.path.join(OUTPUT_DIR, 'action_map.npy'), np.array(all_actions))
    
    print("\n‚úÖ ƒê√£ l∆∞u dataset th√†nh c√¥ng!")
    print(f"- X.npy: {X.shape}")
    print(f"- y.npy: {y.shape}")
    print(f"- action_map.npy: {len(all_actions)} nh√£n")

if __name__ == '__main__':
    prepare_dataset()
